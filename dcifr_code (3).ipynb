{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import *\n",
    "from deepface import DeepFace \n",
    "import sys\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/melin/rob1.jpg\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) c:\\users\\appveyor\\appdata\\local\\temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<1,-1,-1>,struct cv::impl::A0x0dcde1de::Set<3,4,-1>,struct cv::impl::A0x0dcde1de::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 4 (CV_32S)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c906167b6596>\u001b[0m in \u001b[0;36mget_image_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_face_show\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuslts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-c906167b6596>\u001b[0m in \u001b[0;36mdetect_face_show\u001b[1;34m(self, fpath)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'faces'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_num\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mface_num\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepFace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'race'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_detection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deepface\\DeepFace.py\u001b[0m in \u001b[0;36manalyze\u001b[1;34m(img_path, actions, models, enforce_detection, detector_backend)\u001b[0m\n\u001b[0;32m    407\u001b[0m                         \u001b[1;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'race'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mimg_224\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                                         \u001b[0mimg_224\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_detection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menforce_detection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector_backend\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#just emotion model expects grayscale images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m                                 \u001b[0mrace_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'race'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m                                 \u001b[0mrace_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'asian'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'indian'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'black'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'middle eastern'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'latino hispanic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deepface\\commons\\functions.py\u001b[0m in \u001b[0;36mpreprocess_face\u001b[1;34m(img, target_size, grayscale, enforce_detection, detector_backend)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0mbase_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_face\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetector_backend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrayscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_detection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menforce_detection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m         \u001b[1;31m#--------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\deepface\\commons\\functions.py\u001b[0m in \u001b[0;36mdetect_face\u001b[1;34m(img, detector_backend, grayscale, enforce_detection)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mdetector_backend\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mtcnn'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m                 \u001b[0mimg_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#mtcnn expects RGB but OpenCV read BGR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m                 \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_rgb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) c:\\users\\appveyor\\appdata\\local\\temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:94: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<1,-1,-1>,struct cv::impl::A0x0dcde1de::Set<3,4,-1>,struct cv::impl::A0x0dcde1de::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Unsupported depth of input image:\n>     'VDepth::contains(depth)'\n> where\n>     'depth' is 4 (CV_32S)\n"
     ]
    }
   ],
   "source": [
    "#threshold value is collected from slider, but no deepface yet\n",
    "threshold = 50\n",
    "\n",
    "#setting up data for results\n",
    "data = pd.DataFrame()\n",
    "\n",
    "results = \"\"\n",
    "\n",
    "#list of characteristics to analyze - page 1 check boxes\n",
    "analyze_list = []\n",
    "\n",
    "#data = pd.concat([_pic, _age, _gender, _race, _white, _black, _latino_hispanic, _asian, _indian, _middle_eastern], axis=1)\n",
    "#data.columns = ['Source', 'Age', \"Gender\", \"Race\", \"White\", \"Black\", \"Latino/Hispanic\", \"Asian\", \"Indian\", \"MiddleEastern\"]\n",
    "\n",
    "class QComboBox(QtWidgets.QComboBox):\n",
    "    def __init__(self, parent=None):\n",
    "        super(QIComboBox, self).__init__(parent)\n",
    "        \n",
    "class Wizard(QtWidgets.QWizard):\n",
    "    \n",
    "    #redefining nextId\n",
    "    def nextId(self):\n",
    "        id = self.currentId()\n",
    "        if id == 2:\n",
    "            if self.page2.batch_cb.isChecked():\n",
    "                return 5\n",
    "            else:\n",
    "                return 3\n",
    "        if id == 1:\n",
    "            return 2\n",
    "        if id == 3:\n",
    "            return 4\n",
    "        if id == 5:\n",
    "            return 6\n",
    "        # ensures no next button - finishes on either of these based on check boxes\n",
    "        if id == 6 or id == 4:\n",
    "            return -1\n",
    "\n",
    "    def __init__(self, parent=None):\n",
    "        super(Wizard, self).__init__(parent)\n",
    "\n",
    "        #add page 1,2\n",
    "        self.page1 = Page1()\n",
    "        self.setPage(1, self.page1)\n",
    "        \n",
    "        self.page2 = Page2()\n",
    "        self.setPage(2, self.page2)\n",
    "        \n",
    "        self.setStartId(1)\n",
    "        \n",
    "        #set ids for all potential pages\n",
    "        #id = 3\n",
    "        self.page3single = Page3Single()\n",
    "        self.page3singleid = self.setPage(3, self.page3single)\n",
    "        \n",
    "        #id = 4\n",
    "        self.page4single = Page4Single()\n",
    "        self.page4single.setFinalPage(True)\n",
    "        self.page4singleid = self.setPage(4, self.page4single)\n",
    "        \n",
    "        #id = 5\n",
    "        self.page3batch = Page3Batch()\n",
    "        self.page3batchid = self.setPage(5, self.page3batch)\n",
    "        \n",
    "        #id = 6\n",
    "        self.page4batch = Page4Batch()\n",
    "        self.page4batch.setFinalPage(True)\n",
    "        self.page4batchid = self.setPage(6, self.page4batch)\n",
    "        \n",
    "        self.setWindowTitle(\"DCiFR\")\n",
    "        self.setGeometry(0, 0, 800, 600)\n",
    "    \n",
    "# page 1 - select desired attributes for analyzing\n",
    "class Page1(QtWidgets.QWizardPage):\n",
    "    # doesn't account for multiple checks\n",
    "    def btnstate(self,b):\n",
    "        if b.isChecked() == True:\n",
    "            add = b.text().lower()\n",
    "            if add not in analyze_list:\n",
    "                analyze_list.append(add)\n",
    "        elif b.isChecked() == False:\n",
    "            if b.text().lower() in analyze_list:\n",
    "                analyze_list.remove(b.text().lower())\n",
    "                \n",
    "    def ValueContrast(self, value):\n",
    "        threshold = value\n",
    "        \n",
    "    def __init__(self, parent=None):\n",
    "        super(Page1, self).__init__(parent)\n",
    "        \n",
    "        self.title_label = QLabel('Welcome to DCiFR!', self)\n",
    "        self.title_label.move(50, 30)\n",
    "        self.title_label.setFont(QFont('Arial', 20))\n",
    "        self.title_label.adjustSize()\n",
    "\n",
    "        self.title_label = QLabel('Attributes', self)\n",
    "        self.title_label.move(100, 75)\n",
    "        self.title_label.setFont(QFont('Arial', 15))\n",
    "        self.title_label.adjustSize()\n",
    "\n",
    "        #hover info \n",
    "        info = QLabel('Check the boxes that apply. Hover for more info!', self)\n",
    "        info.move(50, 125)\n",
    "        info.setFont(QFont('Arial', 10))\n",
    "        info.adjustSize()\n",
    "        myFont=QtGui.QFont()\n",
    "        myFont.setItalic(True)\n",
    "        info.setFont(myFont)\n",
    "        info.adjustSize()\n",
    "        \n",
    "        #Check boxes\n",
    "        self.age_cb = QCheckBox('Age', self)\n",
    "        self.age_cb.move(50, 150)\n",
    "        self.race_cb = QCheckBox('Race', self)\n",
    "        self.race_cb.move(50, 200)\n",
    "        self.age_cb.adjustSize()\n",
    "        self.race_cb.adjustSize()\n",
    "        self.gender_cb = QCheckBox('Gender', self)\n",
    "        self.gender_cb.move(50, 250)\n",
    "        self.emotion_cb = QCheckBox('Emotion', self)\n",
    "        self.emotion_cb.move(50, 300)\n",
    "        self.gender_cb.adjustSize()\n",
    "        self.emotion_cb.adjustSize()\n",
    "        \n",
    "        self.age_cb.stateChanged.connect(lambda:self.btnstate(self.age_cb))\n",
    "        self.race_cb.stateChanged.connect(lambda:self.btnstate(self.race_cb))\n",
    "        self.gender_cb.stateChanged.connect(lambda:self.btnstate(self.gender_cb))\n",
    "        self.emotion_cb.stateChanged.connect(lambda:self.btnstate(self.emotion_cb))\n",
    "\n",
    "        #Adding slider for race attribute\n",
    "        self.sld = QSlider(Qt.Horizontal, self)\n",
    "        self.sld.setRange(0, 100)\n",
    "        self.sld.move(500, 240)\n",
    "        self.sld.setTickInterval(10)\n",
    "        label = QLabel('Please select your threshold value \\n(only applicable if you select the race attribute)', self)\n",
    "        label.move(300, 150)\n",
    "        minlabel = QLabel('0', self)\n",
    "        minlabel.move(500, 260)\n",
    "        maxlabel = QLabel('100', self)\n",
    "        maxlabel.move(570, 260)\n",
    "        q1label = QLabel('25', self)\n",
    "        q1label.move(510, 260)\n",
    "        medlabel = QLabel('50', self)\n",
    "        medlabel.move(530, 260)\n",
    "        q3label = QLabel('75', self)\n",
    "        q3label.move(550, 260)\n",
    "        minlabel.setFont(QFont('Arial', 5))\n",
    "        maxlabel.setFont(QFont('Arial', 5))\n",
    "        q1label.setFont(QFont('Arial', 5))\n",
    "        medlabel.setFont(QFont('Arial', 5))\n",
    "        q3label.setFont(QFont('Arial', 5))\n",
    "        minlabel.adjustSize()\n",
    "        maxlabel.adjustSize()\n",
    "        q1label.adjustSize()\n",
    "        medlabel.adjustSize()\n",
    "        q3label.adjustSize()\n",
    "        \n",
    "        # tool tip\n",
    "        self.sld.setToolTip('This is a slider for the threshold of the race attribute.')\n",
    "            # need to connect slider value to changing threshold value\n",
    "        self.sld.valueChanged[int].connect(self.ValueContrast)\n",
    "        \n",
    "        #Hovers\n",
    "        self.age_cb.setToolTip('Check this box if you would like to analyze the age of the subject in your image(s)')\n",
    "        self.race_cb.setToolTip('Check this box if you would like to analyze the race of the subject in your image(s)')\n",
    "        self.gender_cb.setToolTip('Check this box if you would like to analyze the gender of the subject in your image(s)')\n",
    "        self.emotion_cb.setToolTip('Check this box if you would like to analyze the emotion of the subject in your image(s)')\n",
    "        \n",
    "#page 2 - choose single or batch mode        \n",
    "class Page2(QtWidgets.QWizardPage):\n",
    "    def __init__(self, parent=None):\n",
    "        super(Page2, self).__init__(parent)\n",
    "        self.title_label = QLabel('DCiFR', self)\n",
    "        self.title_label.move(50, 30)\n",
    "        self.title_label.setFont(QFont('Arial', 20))\n",
    "        self.title_label.adjustSize()\n",
    "        \n",
    "        self.title_label = QLabel('Single or Batch Mode', self)\n",
    "        self.title_label.move(100, 75)\n",
    "        self.title_label.setFont(QFont('Arial', 15))\n",
    "        self.title_label.adjustSize()\n",
    "        #hover info \n",
    "        info = QLabel('Check the box that applies. Hover for more info!', self)\n",
    "        info.move(50, 125)\n",
    "        info.setFont(QFont('Arial', 10))\n",
    "        info.adjustSize()\n",
    "        myFont=QtGui.QFont()\n",
    "        myFont.setItalic(True)\n",
    "        info.setFont(myFont)\n",
    "        info.adjustSize()\n",
    "        \n",
    "        #Check boxes - hbox allows these to be exclusive\n",
    "        hbox = QHBoxLayout()\n",
    "    \n",
    "        self.single_cb = QCheckBox('Single Image', self)\n",
    "        self.single_cb.move(50, 150)\n",
    "        self.batch_cb = QCheckBox('Batch Mode', self)\n",
    "        self.batch_cb.move(50, 200)\n",
    "        self.single_cb.adjustSize()\n",
    "        self.batch_cb.adjustSize()\n",
    "\n",
    "        group = QButtonGroup(self)\n",
    "        group.addButton(self.single_cb)\n",
    "        group.addButton(self.batch_cb)\n",
    "        \n",
    "        hbox.addWidget(self.single_cb)\n",
    "        hbox.addWidget(self.batch_cb)\n",
    "        \n",
    "        #Hovers\n",
    "        self.single_cb.setToolTip('Check this box if you would like to analyze demograhpics for a single image')\n",
    "        self.batch_cb.setToolTip('Check this box if you would like to analyze demograhpics for more than one image')\n",
    "\n",
    "# file upload\n",
    "class Page3Single(QtWidgets.QWizardPage):\n",
    "    #upload and analyze a single image\n",
    "    \n",
    "    #function should produce a csv file with output\n",
    "    def analyze_image(self, results):\n",
    "        age = \"\"\n",
    "        race = \"\"\n",
    "        gender = \"\"\n",
    "        emotion = \"\"\n",
    "        for item in analyze_list:\n",
    "            if item == \"age\":\n",
    "                age = results['age']\n",
    "            elif item == \"race\":\n",
    "                race = results['dominant_race']\n",
    "            elif item == \"gender\":\n",
    "                gender = results['gender']\n",
    "            elif item == \"emotion\":\n",
    "                emotion = results['dominant_emotion']\n",
    "        with open('dcifr_results.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Age\", \"Dominant Race\", \"Gender\", \"Emotion\"])\n",
    "            writer.writerow([age, race, gender, emotion])\n",
    "    \n",
    "    def detect_face_show(self, fpath):\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        img = cv2.imread(fpath)\n",
    "        if img is None:\n",
    "            return(0)\n",
    "        else:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            face_num = len(faces)\n",
    "            if (face_num == 1):\n",
    "                results = DeepFace.analyze(img, analyze_list, enforce_detection=False)\n",
    "                print(results)\n",
    "                self.analyze_image(results)\n",
    "            else:\n",
    "                return(0)\n",
    "    \n",
    "    def get_image_file(self):\n",
    "            dialog = QFileDialog()\n",
    "            file_name = dialog.getOpenFileName(self, 'Open image')\n",
    "            file = os.path.join(file_name[0])\n",
    "            print(file)\n",
    "            self.detect_face_show(file)\n",
    "                \n",
    "    def __init__(self, parent=None):\n",
    "        super(Page3Single, self).__init__(parent)\n",
    "        self.title_label = QLabel('DCiFR', self)\n",
    "        self.title_label.move(50, 30)\n",
    "        self.title_label.setFont(QFont('Arial', 20))\n",
    "        self.title_label.adjustSize()\n",
    "        self.title_label = QLabel('Upload Your Image Below', self)\n",
    "        self.title_label.move(100, 75)\n",
    "        self.title_label.setFont(QFont('Arial', 10))\n",
    "        self.title_label.adjustSize()\n",
    "        \n",
    "        self.button1 = QPushButton(\"Select An Image to Upload Here\", self)  \n",
    "        self.button1.clicked.connect(self.get_image_file) \n",
    "        self.button1.move(50, 150)\n",
    "        \n",
    "class Page3Batch(QtWidgets.QWizardPage):\n",
    "    #upload and analyze multiple images\n",
    "    #def analyze(self, reuslts):\n",
    "        #this function will format and output the results correctly. \n",
    "        \n",
    "    #def detect_face_show(self, fpath):\n",
    "        # this function needs to loop through all of the files in the given folder and analyze each of their results, \n",
    "        # storing in a csv file. if there are multiple faces, it will not analyze.\n",
    "    def detect_face_show_multiple(self, folderpath):\n",
    "        for filename in os.listdir(folderpath):\n",
    "            f = os.path.join(folderpath, filename) # slashes are the wrong way??\n",
    "            print(f)\n",
    "\n",
    "    def get_image_files(self):\n",
    "        dialog = QFileDialog()\n",
    "        dialog.setOption(dialog.DontUseNativeDialog, True)\n",
    "        file_name = dialog.getExistingDirectory(self, \"Select A Folder\")\n",
    "        file = os.path.join(file_name)\n",
    "        print(file)\n",
    "        self.detect_face_show_multiple(file)\n",
    "        \n",
    "    def __init__(self, parent=None):\n",
    "        super(Page3Batch, self).__init__(parent)\n",
    "        self.title_label = QLabel('DCiFR', self)\n",
    "        self.title_label.move(50, 30)\n",
    "        self.title_label.setFont(QFont('Arial', 20))\n",
    "        self.title_label.adjustSize()\n",
    "        self.title_label = QLabel('Upload Your Images Below', self)\n",
    "        self.title_label.move(100, 75)\n",
    "        self.title_label.setFont(QFont('Arial', 10))\n",
    "        self.title_label.adjustSize()\n",
    "        \n",
    "        self.button1 = QPushButton(\"Select Your Folder of Images to Upload Here\", self)   \n",
    "        self.button1.clicked.connect(self.get_image_files)\n",
    "        self.button1.move(50, 150)\n",
    "        \n",
    "    def analyze_images(self, reuslts):\n",
    "        age_ = []\n",
    "        gender_ = []\n",
    "        race_ = []\n",
    "        emotion_ = []\n",
    "        asian_ = []\n",
    "        black_ = []\n",
    "        indian_ = []\n",
    "        latino_hispanic_ = []\n",
    "        middle_eastern_ = []\n",
    "        white_ = []\n",
    "        \n",
    "        for i in range(len(results)):\n",
    "            age = results[i]['age']\n",
    "            gender = results[i]['gender']\n",
    "            race = results[i]['dominant_race']\n",
    "            emotion = results[i]['emotion']\n",
    "            asian = results[i]['race']['asian']\n",
    "            black = results[i]['race']['black']\n",
    "            indian = results[i]['race']['indian']\n",
    "            latino_hispanic = results[i]['race']['latino hispanic']\n",
    "            middle_eastern = results[i]['race']['middle eastern']\n",
    "            white = results[i]['race']['white']\n",
    "        \n",
    "            age_.append(age)\n",
    "            gender_.append(gender)\n",
    "            race_.append(race)\n",
    "            emotion_.append(emotion)\n",
    "            black_.append(black)\n",
    "            indian_.append(indian)\n",
    "            latino_hispanic_.append(latino_hispanic)\n",
    "            middle_eastern_.append(middle_eastern)\n",
    "            white_.append(white)\n",
    "        \n",
    "        _pic = pd.DataFrame(pics)\n",
    "        _age = pd.DataFrame(age_)\n",
    "        _gender = pd.DataFrame(gender_)\n",
    "        _emotion = pd.DataFrame(emotion_)\n",
    "        _race = pd.DataFrame(race_)\n",
    "        _white = pd.DataFrame(white_)\n",
    "        _black = pd.DataFrame(black_)\n",
    "        _latino_hispanic = pd.DataFrame(latino_hispanic_)\n",
    "        _asian = pd.DataFrame(asian_)\n",
    "        _indian = pd.DataFrame(indian_)\n",
    "        _middle_eastern = pd.DataFrame(middle_eastern_)\n",
    "        \n",
    "        data = pd.concat([_pic, _age, _gender, _race, _white, _black, _latino_hispanic, _asian, _indian, _middle_eastern], axis=1)\n",
    "        \n",
    "#results\n",
    "class Page4Single(QtWidgets.QWizardPage):\n",
    "    def __init__(self, parent=None):\n",
    "        super(Page4Single, self).__init__(parent)\n",
    "        \n",
    "        self.title_label = QLabel('DCiFR', self)\n",
    "        self.title_label.move(50, 30)\n",
    "        self.title_label.setFont(QFont('Arial', 20))\n",
    "        self.title_label.adjustSize()\n",
    "\n",
    "        self.title_label = QLabel('Results', self)\n",
    "        self.title_label.move(100, 75)\n",
    "        self.title_label.setFont(QFont('Arial', 15))\n",
    "        self.title_label.adjustSize()\n",
    "        self.title_label = QLabel('Here are the results for the IMAGE you uploaded:', self)\n",
    "        self.title_label.move(100, 125)\n",
    "        self.title_label.setFont(QFont('Arial', 10))\n",
    "        self.title_label.adjustSize()\n",
    "        \n",
    "        results_label = QLabel(\"Please check your working directory for a CSV results file\", self)\n",
    "        print(analyze_results)\n",
    "        results_label.move(125, 150)\n",
    "        results_label.setFont(QFont('Arial', 15))\n",
    "        results_label.adjustSize()\n",
    "        \n",
    "class Page4Batch(QtWidgets.QWizardPage):\n",
    "    def __init__(self, parent=None):\n",
    "        super(Page4Batch, self).__init__(parent)\n",
    "        \n",
    "        self.title_label = QLabel('DCiFR', self)\n",
    "        self.title_label.move(50, 30)\n",
    "        self.title_label.setFont(QFont('Arial', 20))\n",
    "        self.title_label.adjustSize()\n",
    "\n",
    "        self.title_label = QLabel('Results', self)\n",
    "        self.title_label.move(100, 75)\n",
    "        self.title_label.setFont(QFont('Arial', 15))\n",
    "        self.title_label.adjustSize()\n",
    "        self.title_label = QLabel('Here are the results for the IMAGES you uploaded:', self)\n",
    "        self.title_label.move(100, 125)\n",
    "        self.title_label.setFont(QFont('Arial', 10))\n",
    "        self.title_label.adjustSize()\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    wizard = Wizard()\n",
    "    wizard.show()\n",
    "    app.exec_()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
